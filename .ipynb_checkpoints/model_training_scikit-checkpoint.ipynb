{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff04875a-20e1-4f8b-947b-7603e1d3d5d3",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fddd9f-041d-40e9-8fa0-a743f51facf0",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09de833d-9c3e-4ac3-9461-459d77cf2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pywt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# importing libraries required for model building and \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# importing a library for visualization\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "# importing libraries to save the ML model and create JSON files\n",
    "\n",
    "import joblib \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82603242-55b9-4a91-9100-047d29ac0827",
   "metadata": {},
   "source": [
    "### Creating a list of all folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6536dc40-0d33-4344-bd0a-92568a31a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_folders(directory):\n",
    "    folders = []\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            folders.append(entry)\n",
    "    return folders\n",
    "\n",
    "# Specify the directory you want to list folders from\n",
    "directory_path = 'cropped_images/'\n",
    "\n",
    "# Get the list of folder names\n",
    "folder_names = list_folders(directory_path)\n",
    "\n",
    "# folder_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ef224-9e2b-4a50-8325-c49cbdd3b58e",
   "metadata": {},
   "source": [
    "### Creating a dictionary of player name with all the image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04230b9a-9383-403c-8521-110120f45b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a list of folder names of cropped images\n",
    "\n",
    "cropped_folder_list = folder_names\n",
    "\n",
    "folder_path_dict = {'Name':[],\n",
    "                    'Paths':[]}\n",
    "\n",
    "\n",
    "\n",
    "for folder_name in cropped_folder_list:\n",
    "    \n",
    "    list_1 = []\n",
    "\n",
    "    folder_path = 'cropped_images'+'/{}'.format(folder_name)\n",
    "\n",
    "    # Get a list of all files and directories in the specified folder\n",
    "    files_and_directories = os.listdir(folder_path)\n",
    "\n",
    "    # Filter only files (not directories) if needed\n",
    "    files = [f for f in files_and_directories if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Now 'files' contains a list of file names in the folder\n",
    "    # You can also get the full paths by using os.path.join() on each file name\n",
    "    file_paths = [os.path.join(folder_path, f) for f in files]\n",
    "    \n",
    "    # changing the folder name into a proper name to be used as the dictionary key\n",
    "    \n",
    "    original_string = folder_name\n",
    "\n",
    "    # Split the string based on underscores\n",
    "    parts = original_string.split('_')\n",
    "\n",
    "    # Join the first two parts with spaces\n",
    "    clean_name = ' '.join(parts[:2])\n",
    "\n",
    "\n",
    "    # Print the file paths\n",
    "    for file_path in file_paths:\n",
    "        list_1.append(file_path)\n",
    "    \n",
    "    folder_path_dict['Name'].append(clean_name)\n",
    "    folder_path_dict['Paths'].append(list_1)\n",
    "    \n",
    "# folder_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365cb9d4-35b1-4eb5-8b39-ceb67d5f19ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alex albon',\n",
       " 'carlos sainz',\n",
       " 'charles leclerc',\n",
       " 'daniel ricciardo',\n",
       " 'esteban ocon',\n",
       " 'fernando alonso',\n",
       " 'george russell',\n",
       " 'kevin magnussen',\n",
       " 'lance stroll',\n",
       " 'lando norris',\n",
       " 'lewis hamilton',\n",
       " 'logan sargeant',\n",
       " 'max verstappen',\n",
       " 'nico hulkenberg',\n",
       " 'oscar piastri',\n",
       " 'pierre gasly',\n",
       " 'sergio perez',\n",
       " 'valtteri bottas',\n",
       " 'yuki tsunoda',\n",
       " 'zhou guanyu']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "folder_path_dict['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61535d99-6726-4c7b-8a43-0944ca1b4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path_dict['Paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922ee02-5e58-4043-b23a-0bcfa57f4007",
   "metadata": {},
   "source": [
    "### Converting racer names into numeric classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea72906-53d2-4786-9b73-fd9f444b9d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alex albon': 0,\n",
       " 'carlos sainz': 1,\n",
       " 'charles leclerc': 2,\n",
       " 'daniel ricciardo': 3,\n",
       " 'esteban ocon': 4,\n",
       " 'fernando alonso': 5,\n",
       " 'george russell': 6,\n",
       " 'kevin magnussen': 7,\n",
       " 'lance stroll': 8,\n",
       " 'lando norris': 9,\n",
       " 'lewis hamilton': 10,\n",
       " 'logan sargeant': 11,\n",
       " 'max verstappen': 12,\n",
       " 'nico hulkenberg': 13,\n",
       " 'oscar piastri': 14,\n",
       " 'pierre gasly': 15,\n",
       " 'sergio perez': 16,\n",
       " 'valtteri bottas': 17,\n",
       " 'yuki tsunoda': 18,\n",
       " 'zhou guanyu': 19}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "\n",
    "count = 0\n",
    "for racer_name in folder_path_dict['Name']:\n",
    "    class_dict[racer_name] = count\n",
    "    count = count + 1\n",
    "    \n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feba962-e9ff-4886-9461-1f94efbc0855",
   "metadata": {},
   "source": [
    "### Creating a function for wavelet transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc06b0e-39af-465b-94ab-85f0861aa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b48c9a-7230-4737-ae66-b2807dc218a8",
   "metadata": {},
   "source": [
    "# Model Improvement Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4498b5-70c7-40d8-8026-73190d6b9742",
   "metadata": {},
   "source": [
    "- Raw image resized to 32x32 (m_1)\n",
    "- Raw image resized to 64x64 (m_2)\n",
    "- Histogram equalized image at 64x64 (m_3)\n",
    "- Raw image resized at 64x64 + Histogram equalized image at 64x64 (vertically stacked) (m_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967db235-fc83-4b19-baab-bdcf0fb16a2c",
   "metadata": {},
   "source": [
    "### Creating the X and y variables for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d3d696-d6c4-4931-8550-d126470e29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw,y_raw = [], []\n",
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        X_raw.append(scaled_raw_img)\n",
    "        y_raw.append(class_dict[racer_name]) \n",
    "            \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739bff69-80da-4f23-8774-0f1755d7cc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cdc9f77-043d-46da-92c7-4a850637cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is a list of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ec38ea-f874-4f79-9210-da45bb08e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ad293b-4c1f-45d3-a658-353810a4c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 3072, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = np.array(X)\n",
    "x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dcff1f5-9419-4881-8435-ae63d8538380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea9cd1-ea5e-4759-b812-c49f36ae0019",
   "metadata": {},
   "source": [
    "### Reshaping X and also updating the numbers to be as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9804421d-de73-4d54-b899-5b44c4220dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 3072)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),3072).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0266d19-cd00-4228-848c-317bb68e708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ba9e72-0e1b-494f-98fd-60bf93a31893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a48e20-1e07-48d0-9836-27f0da463499",
   "metadata": {},
   "source": [
    "## 1. Raw image resized to 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874011a1-8a7d-48ab-9fc1-ea0ee1e00be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# pipe_1 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "#                  ('svc', SVC(kernel = 'rbf', C = 10)) # Step 2: Train a model\n",
    "#                 ])\n",
    "\n",
    "# pipe_1.fit(X_train_1, y_train_1)\n",
    "# m_1 = pipe_1.score(X_test_1, y_test_1)\n",
    "# print(m_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ae5a80-4cfa-4a18-a385-e5e13ebf0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc06cf-d29b-4b96-b80d-41df482de564",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (SVM vs Random Forest vs Logistic Regression)\n",
    "\n",
    "##### We are only using 32x32 (m_1) data for hyperparameter tuning due to low computaional power of my PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276e1a09-4854-4d59-9261-ad8c24dbea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac89bdd4-ff9c-4b22-a1fa-9c9be73f5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.598152</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.253385</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.644608</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.598152   \n",
       "1        random_forest    0.253385   \n",
       "2  logistic_regression    0.644608   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                  {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train_1, y_train_1)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b72ac8a-5d53-474b-ab54-e3fbf659134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('svc',\n",
       "                  SVC(C=1, gamma='auto', kernel='linear', probability=True))]),\n",
       " 'random_forest': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier',\n",
       "                  RandomForestClassifier(n_estimators=10))]),\n",
       " 'logistic_regression': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression',\n",
       "                  LogisticRegression(C=1, solver='liblinear'))])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f2856-c78d-40b0-b799-d6f5aa6c6677",
   "metadata": {},
   "source": [
    "### Testing the model performance with the test data set (not the validation data set as done in the hyperparemeter tuning step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dbac07f-c28a-411b-8cba-d50b7806fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVM Model is 0.6223628691983122\n",
      "Accuracy of the Random Forest Model is 0.2721518987341772\n",
      "Accuracy of the Logistic Regression Model is 0.6624472573839663\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the SVM Model is {best_estimators['svm'].score(X_test_1,y_test_1)}\")\n",
    "print(f\"Accuracy of the Random Forest Model is {best_estimators['random_forest'].score(X_test_1,y_test_1)}\")\n",
    "print(f\"Accuracy of the Logistic Regression Model is {best_estimators['logistic_regression'].score(X_test_1,y_test_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eb2970e-3ebe-4e8f-9b22-ef4c5737cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc76cb8c-ec62-48f8-be2e-3a023461e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c45fee-0545-4e4a-8686-3f30b6f7b580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b5d8c-e2f1-4954-b11e-b6deda3da41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e75adf7-cfec-4561-be86-f758121efaef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_sample\u001b[49m(X_test, y_test, class_dict, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_sample' is not defined"
     ]
    }
   ],
   "source": [
    "# plot_sample(X_test, y_test, class_dict, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83e2e3cf-dd27-438e-97e8-a73439bffa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a fucntion to get the key when a value is given\n",
    "\n",
    "def get_key_from_value(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    return None \n",
    "\n",
    "# plot a sample of the image being tested\n",
    "\n",
    "def plot_sample(X,y, dicti,index):\n",
    "    plt.figure(figsize = (15,3))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(get_key_from_value(dicti,y[index]))\n",
    "\n",
    "\n",
    "def check_output(x):\n",
    "    \n",
    "    # predicting the driver\n",
    "    \n",
    "    prediction = np.round(best_estimators['logistic_regression'].predict(np.expand_dims(X_test_1[x], axis=0))[0])\n",
    "    \n",
    "    \n",
    "    # finding the probabilities assigned to each driver by the LR model\n",
    "\n",
    "    percentages = np.round(best_estimators['logistic_regression'].predict_proba(X_test_1[x].reshape(1,-1))*100,1)[0]\n",
    "    \n",
    "    \n",
    "    #finding the highest probability from the above list\n",
    "\n",
    "    highest_perc = np.max(percentages)\n",
    "    \n",
    "    \n",
    "    # formatting\n",
    "\n",
    "    converted_array = np.array([(\"{:.2f}\".format(number)) for number in percentages])\n",
    "\n",
    "    converted_highest_perc = \"{:.2f}%\".format(highest_perc)\n",
    "\n",
    "    driver_name = f\"The predicted driver is {get_key_from_value(class_dict,prediction)} with a {converted_highest_perc} probability\"\n",
    "    \n",
    "    plot_sample(X_test,y_test,class_dict,x) \n",
    "\n",
    "    return driver_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dd465de-56a3-4407-8334-24e6d0ed5448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The predicted driver is oscar piastri with a 77.10% probability'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_output(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5b5c5-ebb8-450b-a9e8-73ebd17ef770",
   "metadata": {},
   "source": [
    "### <font color='yellow'> Since the best performing model is Logistic regression, we will be using that in our next steps <font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee78813-c087-4cd1-b257-b26070a81c14",
   "metadata": {},
   "source": [
    "## 2. Raw image resized to 64x64 (m_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd294c29-e00f-42b0-ac9b-58e5f3b6a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "        # print(racer_name)\n",
    "        # print(training_image)\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        # scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        # m_2\n",
    "        scaled_raw_img = cv2.resize(img,(64,64))\n",
    "        \n",
    "        # m_3\n",
    "        # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # equ = cv2.equalizeHist(img_gray)\n",
    "        # scaled_img_hist = cv2.resize(equ, (64, 64))\n",
    "        \n",
    "        # m_4\n",
    "        # combined_img = np.vstack((scaled_raw_img.reshape(64*64*3,1),scaled_img_hist.reshape(64*64,1)))\n",
    "        \n",
    "        \n",
    "        # reshaped final image\n",
    "        \n",
    "        # m_1\n",
    "        # final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        # m_2\n",
    "        final_img = scaled_raw_img.reshape(64*64*3,1) \n",
    "        \n",
    "         # m_3\n",
    "        # final_img = scaled_img_hist.reshape(64*64,1)\n",
    "        \n",
    "        # m_4\n",
    "        \n",
    "        # final_img = combined_img.reshape(64*64*4,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c8254fa-d0b2-40f3-be31-0d2100664491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 12288)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),12288).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38a18f-5529-422b-b016-22712c7886c0",
   "metadata": {},
   "source": [
    "{'svm': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                 ('svc',\n",
    "                  SVC(C=1, gamma='auto', kernel='linear', probability=True))]),\n",
    " 'random_forest': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                 ('randomforestclassifier',\n",
    "                  RandomForestClassifier(n_estimators=10))]),\n",
    " 'logistic_regression': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                 ('logisticregression',\n",
    "                  LogisticRegression(C=1, solver='liblinear'))])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6118929-a31b-4e5c-89c5-7effad62909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455696202531646\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_2 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('logisticregression', LogisticRegression(solver = 'liblinear', C = 1)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_2.fit(X_train, y_train)\n",
    "m_2 = pipe_2.score(X_test, y_test)\n",
    "print(m_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32578f-c5b5-4e3d-a774-7cdd105746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83755651-51c9-4185-9650-3181d5aa0284",
   "metadata": {},
   "source": [
    "### Checking what the model output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806366d-19b7-4d28-ae48-76eae2688d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction = pipe_2.predict((X_test[5].reshape(1,-1)))[0]\n",
    "\n",
    "print(prediction)\n",
    "print(type(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabcb5a-f546-4d12-850e-7958e8ee091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = (np.round(pipe_2.predict_proba(X_test[5].reshape(1,-1))[0]*100,decimals=2).tolist()[0])\n",
    "\n",
    "converted_array = np.array([(\"{:.2f}\".format(number)) for number in percentages])\n",
    "\n",
    "print(converted_array)\n",
    "print(type(converted_array))\n",
    "print(converted_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5dd7a-aa10-4624-b7cb-b1660a2cc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbceb4-c0f4-489c-acc8-b0c7dd6463dc",
   "metadata": {},
   "source": [
    "### Saving the model as pickle file  and create a class dictionary as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac4e959f-0806-45b8-b9db-946b8c7ee916",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['logistic_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60df9ba3-e20c-470c-950d-34d2d791ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(pipe_2, open('server/artifacts/saved_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0d91a76-92ae-43c8-904e-b5b7a3676225",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"server/artifacts/class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63741375-7979-4c79-90e6-2196bf8f5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60e4c5-9e15-48bc-b217-d824e38bd20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81131a10-9537-49b4-915d-990e9aa56bf6",
   "metadata": {},
   "source": [
    "# <font color='red'> ^^^^^^^^^^^^ Only include upto here in your article <font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbd3ac-b9c8-4ecf-a156-b10cd8a4ee69",
   "metadata": {},
   "source": [
    "## 3. Histogram equalized image at 64x64 (m_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31be171-e7ed-4150-a0c5-a20f8bbd06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "        # print(racer_name)\n",
    "        # print(training_image)\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        # scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        # m_2\n",
    "        # scaled_raw_img = cv2.resize(img,(64,64))\n",
    "        \n",
    "        # m_3\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        equ = cv2.equalizeHist(img_gray)\n",
    "        scaled_img_hist = cv2.resize(equ, (64, 64))\n",
    "        \n",
    "        # m_4\n",
    "        # combined_img = np.vstack((scaled_raw_img.reshape(64*64*3,1),scaled_img_hist.reshape(64*64,1)))\n",
    "        \n",
    "        \n",
    "        # reshaped final image\n",
    "        \n",
    "        # m_1\n",
    "        # final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        # m_2\n",
    "        # final_img = scaled_raw_img.reshape(64*64*3,1) \n",
    "        \n",
    "         # m_3\n",
    "        final_img = scaled_img_hist.reshape(64*64,1)\n",
    "        \n",
    "        # m_4\n",
    "        \n",
    "        # final_img = combined_img.reshape(64*64*4,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66de7dd-a17a-4c16-871c-5a7c4fbb8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2acfc9-8602-4565-8ad4-c7324e14b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_3 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('logisticregression', LogisticRegression(solver = 'liblinear', C = 1)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_3.fit(X_train, y_train)\n",
    "m_3 = pipe_3.score(X_test, y_test)\n",
    "print(m_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51a16d-2abf-4b0f-811a-f4579a335fb0",
   "metadata": {},
   "source": [
    "## 4. Raw image resized at 64x64 + Histogram equalized image at 64x64 (vertically stacked) (m_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb23ab5-b3f8-4080-bc39-635685bb3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "        # print(racer_name)\n",
    "        # print(training_image)\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        # scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        # m_2\n",
    "        # scaled_raw_img = cv2.resize(img,(64,64))\n",
    "        \n",
    "        # m_3\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        equ = cv2.equalizeHist(img_gray)\n",
    "        scaled_img_hist = cv2.resize(equ, (64, 64))\n",
    "        \n",
    "        # m_4\n",
    "        combined_img = np.vstack((scaled_raw_img.reshape(64*64*3,1),scaled_img_hist.reshape(64*64,1)))\n",
    "        \n",
    "        \n",
    "        # reshaped final image\n",
    "        \n",
    "        # m_1\n",
    "        # final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        # m_2\n",
    "        # final_img = scaled_raw_img.reshape(64*64*3,1) \n",
    "        \n",
    "         # m_3\n",
    "        # final_img = scaled_img_hist.reshape(64*64,1)\n",
    "        \n",
    "        # m_4\n",
    "        \n",
    "        final_img = combined_img.reshape(64*64*4,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766ec70-dbc1-4c59-aecb-f31e89f46c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),16384).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e0e6a-b372-4e5d-bde0-08fe6168f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_4 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('logisticregression', LogisticRegression(solver = 'liblinear', C = 1)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_4.fit(X_train, y_train)\n",
    "m_4 = pipe_4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd57a2-d162-42e3-8bf5-0c93ae975a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f03c3b-5974-4258-b47b-0914a590357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a summary table of all the methods used and their performance\n",
    "\n",
    "methods = [\"m_1\", \"m_2\", \"m_3\",\"m_4\"]\n",
    "prediction_scores = [m_1, m_2, m_3, m_4]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Method\": methods, \"Prediction Scores\": prediction_scores})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47486185-5e78-46bf-bb56-4f1fee7819af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe7343f6-3a6b-4df1-a6b1-0bc2ed1007ea",
   "metadata": {},
   "source": [
    "## Create a classification report that provides precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3b7e1-38fb-4cea-ace9-97b912f19ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe_4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7862fe4-f00d-45c3-b53c-08c8693a8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like the best we can get is 59% accuracy \n",
    "# we might have to explore CNN \n",
    "\n",
    "# - https://www.youtube.com/watch?v=7HPwo4wnJeA\n",
    "# - https://www.codemag.com/Article/2205081/Implementing-Face-Recognition-Using-Deep-Learning-and-Support-Vector-Machines\n",
    "# - https://thinkingneuron.com/face-recognition-using-deep-learning-cnn-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0aef0-10c9-45d6-b58f-a5ad3e3d1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25eb1f-e4df-4d6b-820b-10a7fccfd1fd",
   "metadata": {},
   "source": [
    "### Choosing the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b934f8-cbea-496d-a396-67657bb470f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_clf = best_estimators['svm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2e36f-85bb-4338-aca5-c3e32a5f7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf92e1a-c2b7-4eb6-bf57-a9fac378df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8804c9e-7301-4e52-a5e6-c4401fe58f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict(X_test[5].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795f05b-2996-4b5f-9ea5-469c97020f82",
   "metadata": {},
   "source": [
    "### Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8058b-3ead-4922-855b-738e026ca928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37dcd4-43e8-40e2-a9be-f259603354f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874e23e-e37b-4bef-8538-675abdecb603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033bb71-3b65-4d18-92a5-40d993b41f2b",
   "metadata": {},
   "source": [
    "### Saving the model as pickle file  and create a class dictionary as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791f4a3-5dac-4c3e-868f-e7386184a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "import pickle\n",
    "\n",
    "pickle.dump(best_clf, open('saved_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d9b1b-0c73-4cea-8025-260efc12ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
