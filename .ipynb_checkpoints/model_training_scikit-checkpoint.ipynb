{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff04875a-20e1-4f8b-947b-7603e1d3d5d3",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fddd9f-041d-40e9-8fa0-a743f51facf0",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09de833d-9c3e-4ac3-9461-459d77cf2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pywt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# importing libraries required for model building and \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# importing a library for visualization\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "# importing libraries to save the ML model and create JSON files\n",
    "\n",
    "import joblib \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82603242-55b9-4a91-9100-047d29ac0827",
   "metadata": {},
   "source": [
    "### Creating a list of all folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6536dc40-0d33-4344-bd0a-92568a31a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_folders(directory):\n",
    "    folders = []\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            folders.append(entry)\n",
    "    return folders\n",
    "\n",
    "# Specify the directory you want to list folders from\n",
    "directory_path = 'cropped_images/'\n",
    "\n",
    "# Get the list of folder names\n",
    "folder_names = list_folders(directory_path)\n",
    "\n",
    "# folder_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ef224-9e2b-4a50-8325-c49cbdd3b58e",
   "metadata": {},
   "source": [
    "### Creating a dictionary of player name with all the image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04230b9a-9383-403c-8521-110120f45b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a list of folder names of cropped images\n",
    "\n",
    "cropped_folder_list = folder_names\n",
    "\n",
    "folder_path_dict = {'Name':[],\n",
    "                    'Paths':[]}\n",
    "\n",
    "\n",
    "\n",
    "for folder_name in cropped_folder_list:\n",
    "    \n",
    "    list_1 = []\n",
    "\n",
    "    folder_path = 'cropped_images'+'/{}'.format(folder_name)\n",
    "\n",
    "    # Get a list of all files and directories in the specified folder\n",
    "    files_and_directories = os.listdir(folder_path)\n",
    "\n",
    "    # Filter only files (not directories) if needed\n",
    "    files = [f for f in files_and_directories if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Now 'files' contains a list of file names in the folder\n",
    "    # You can also get the full paths by using os.path.join() on each file name\n",
    "    file_paths = [os.path.join(folder_path, f) for f in files]\n",
    "    \n",
    "    # changing the folder name into a proper name to be used as the dictionary key\n",
    "    \n",
    "    original_string = folder_name\n",
    "\n",
    "    # Split the string based on underscores\n",
    "    parts = original_string.split('_')\n",
    "\n",
    "    # Join the first two parts with spaces\n",
    "    clean_name = ' '.join(parts[:2])\n",
    "\n",
    "\n",
    "    # Print the file paths\n",
    "    for file_path in file_paths:\n",
    "        list_1.append(file_path)\n",
    "    \n",
    "    folder_path_dict['Name'].append(clean_name)\n",
    "    folder_path_dict['Paths'].append(list_1)\n",
    "    \n",
    "# folder_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365cb9d4-35b1-4eb5-8b39-ceb67d5f19ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alex albon',\n",
       " 'carlos sainz',\n",
       " 'charles leclerc',\n",
       " 'daniel ricciardo',\n",
       " 'esteban ocon',\n",
       " 'fernando alonso',\n",
       " 'george russell',\n",
       " 'kevin magnussen',\n",
       " 'lance stroll',\n",
       " 'lando norris',\n",
       " 'lewis hamilton',\n",
       " 'logan sargeant',\n",
       " 'max verstappen',\n",
       " 'nico hulkenberg',\n",
       " 'oscar piastri',\n",
       " 'pierre gasly',\n",
       " 'sergio perez',\n",
       " 'valtteri bottas',\n",
       " 'yuki tsunoda',\n",
       " 'zhou guanyu']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "folder_path_dict['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61535d99-6726-4c7b-8a43-0944ca1b4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path_dict['Paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922ee02-5e58-4043-b23a-0bcfa57f4007",
   "metadata": {},
   "source": [
    "### Converting racer names into numeric classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea72906-53d2-4786-9b73-fd9f444b9d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alex albon': 0,\n",
       " 'carlos sainz': 1,\n",
       " 'charles leclerc': 2,\n",
       " 'daniel ricciardo': 3,\n",
       " 'esteban ocon': 4,\n",
       " 'fernando alonso': 5,\n",
       " 'george russell': 6,\n",
       " 'kevin magnussen': 7,\n",
       " 'lance stroll': 8,\n",
       " 'lando norris': 9,\n",
       " 'lewis hamilton': 10,\n",
       " 'logan sargeant': 11,\n",
       " 'max verstappen': 12,\n",
       " 'nico hulkenberg': 13,\n",
       " 'oscar piastri': 14,\n",
       " 'pierre gasly': 15,\n",
       " 'sergio perez': 16,\n",
       " 'valtteri bottas': 17,\n",
       " 'yuki tsunoda': 18,\n",
       " 'zhou guanyu': 19}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "\n",
    "count = 0\n",
    "for racer_name in folder_path_dict['Name']:\n",
    "    class_dict[racer_name] = count\n",
    "    count = count + 1\n",
    "    \n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feba962-e9ff-4886-9461-1f94efbc0855",
   "metadata": {},
   "source": [
    "### Creating a function for wavelet transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc06b0e-39af-465b-94ab-85f0861aa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b48c9a-7230-4737-ae66-b2807dc218a8",
   "metadata": {},
   "source": [
    "# Model Improvement Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4498b5-70c7-40d8-8026-73190d6b9742",
   "metadata": {},
   "source": [
    "- Raw image resized to 32x32 (m_1)\n",
    "- Raw image resized to 64x64 (m_2)\n",
    "- Histogram equalized image at 64x64 (m_3)\n",
    "- Raw image resized at 64x64 + Histogram equalized image at 64x64 (vertically stacked) (m_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967db235-fc83-4b19-baab-bdcf0fb16a2c",
   "metadata": {},
   "source": [
    "### Creating the X and y variables for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d3d696-d6c4-4931-8550-d126470e29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea9cd1-ea5e-4759-b812-c49f36ae0019",
   "metadata": {},
   "source": [
    "### Reshaping X and also updating the numbers to be as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9804421d-de73-4d54-b899-5b44c4220dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),3072).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a48e20-1e07-48d0-9836-27f0da463499",
   "metadata": {},
   "source": [
    "## 1. Raw image resized to 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874011a1-8a7d-48ab-9fc1-ea0ee1e00be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5759493670886076\n"
     ]
    }
   ],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_1 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('svc', SVC(kernel = 'rbf', C = 10)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_1.fit(X_train_1, y_train_1)\n",
    "m_1 = pipe_1.score(X_test_1, y_test_1)\n",
    "print(m_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc06cf-d29b-4b96-b80d-41df482de564",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (SVM vs Random Forest vs Logistic Regression)\n",
    "\n",
    "##### We are only using 32x32 (m_1) data for hyperparameter tuning due to low computaional power of my PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "276e1a09-4854-4d59-9261-ad8c24dbea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac89bdd4-ff9c-4b22-a1fa-9c9be73f5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.598152</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.272342</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.644608</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.598152   \n",
       "1        random_forest    0.272342   \n",
       "2  logistic_regression    0.644608   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                  {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train_1, y_train_1)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b72ac8a-5d53-474b-ab54-e3fbf659134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('svc',\n",
       "                  SVC(C=1, gamma='auto', kernel='linear', probability=True))]),\n",
       " 'random_forest': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier',\n",
       "                  RandomForestClassifier(n_estimators=10))]),\n",
       " 'logistic_regression': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression',\n",
       "                  LogisticRegression(C=1, solver='liblinear'))])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f2856-c78d-40b0-b799-d6f5aa6c6677",
   "metadata": {},
   "source": [
    "### Testing the model performance with the test data set (not the validation data set as done in the hyperparemeter tuning step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dbac07f-c28a-411b-8cba-d50b7806fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVM Model is 0.6223628691983122\n",
      "Accuracy of the Random Forest Model is 0.2848101265822785\n",
      "Accuracy of the Logistic Regression Model is 0.6624472573839663\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the SVM Model is {best_estimators['svm'].score(X_test_1,y_test_1)}\")\n",
    "print(f\"Accuracy of the Random Forest Model is {best_estimators['random_forest'].score(X_test_1,y_test_1)}\")\n",
    "print(f\"Accuracy of the Logistic Regression Model is {best_estimators['logistic_regression'].score(X_test_1,y_test_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373ad22-6589-4d03-be7b-ebbce80aef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187aef53-df3c-4d6f-bc28-5fd2176a46c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ee78813-c087-4cd1-b257-b26070a81c14",
   "metadata": {},
   "source": [
    "## 2. Raw image resized to 64x64 (m_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd294c29-e00f-42b0-ac9b-58e5f3b6a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "        # print(racer_name)\n",
    "        # print(training_image)\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        # scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        # m_2\n",
    "        scaled_raw_img = cv2.resize(img,(64,64))\n",
    "        \n",
    "        # m_3\n",
    "        # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # equ = cv2.equalizeHist(img_gray)\n",
    "        # scaled_img_hist = cv2.resize(equ, (64, 64))\n",
    "        \n",
    "        # m_4\n",
    "        # combined_img = np.vstack((scaled_raw_img.reshape(64*64*3,1),scaled_img_hist.reshape(64*64,1)))\n",
    "        \n",
    "        \n",
    "        # reshaped final image\n",
    "        \n",
    "        # m_1\n",
    "        # final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        # m_2\n",
    "        final_img = scaled_raw_img.reshape(64*64*3,1) \n",
    "        \n",
    "         # m_3\n",
    "        # final_img = scaled_img_hist.reshape(64*64,1)\n",
    "        \n",
    "        # m_4\n",
    "        \n",
    "        # final_img = combined_img.reshape(64*64*4,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8254fa-d0b2-40f3-be31-0d2100664491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),12288).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6118929-a31b-4e5c-89c5-7effad62909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_2 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('svc', SVC(kernel = 'rbf', C = 10)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_2.fit(X_train, y_train)\n",
    "m_2 = pipe_2.score(X_test, y_test)\n",
    "print(m_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbd3ac-b9c8-4ecf-a156-b10cd8a4ee69",
   "metadata": {},
   "source": [
    "## 3. Histogram equalized image at 64x64 (m_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31be171-e7ed-4150-a0c5-a20f8bbd06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "        # print(racer_name)\n",
    "        # print(training_image)\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        # scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        # m_2\n",
    "        # scaled_raw_img = cv2.resize(img,(64,64))\n",
    "        \n",
    "        # m_3\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        equ = cv2.equalizeHist(img_gray)\n",
    "        scaled_img_hist = cv2.resize(equ, (64, 64))\n",
    "        \n",
    "        # m_4\n",
    "        # combined_img = np.vstack((scaled_raw_img.reshape(64*64*3,1),scaled_img_hist.reshape(64*64,1)))\n",
    "        \n",
    "        \n",
    "        # reshaped final image\n",
    "        \n",
    "        # m_1\n",
    "        # final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        # m_2\n",
    "        # final_img = scaled_raw_img.reshape(64*64*3,1) \n",
    "        \n",
    "         # m_3\n",
    "        final_img = scaled_img_hist.reshape(64*64,1)\n",
    "        \n",
    "        # m_4\n",
    "        \n",
    "        # final_img = combined_img.reshape(64*64*4,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66de7dd-a17a-4c16-871c-5a7c4fbb8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2acfc9-8602-4565-8ad4-c7324e14b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_3 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('svc', SVC(kernel = 'rbf', C = 10)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_3.fit(X_train, y_train)\n",
    "m_3 = pipe_3.score(X_test, y_test)\n",
    "print(m_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51a16d-2abf-4b0f-811a-f4579a335fb0",
   "metadata": {},
   "source": [
    "## 4. Raw image resized at 64x64 + Histogram equalized image at 64x64 (vertically stacked) (m_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb23ab5-b3f8-4080-bc39-635685bb3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for racer_name, training_files in zip(folder_path_dict['Name'],folder_path_dict['Paths']):\n",
    "    for training_image in training_files: \n",
    "        # print(racer_name)\n",
    "        # print(training_image)\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # m_1\n",
    "        # scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        \n",
    "        # m_2\n",
    "        # scaled_raw_img = cv2.resize(img,(64,64))\n",
    "        \n",
    "        # m_3\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        equ = cv2.equalizeHist(img_gray)\n",
    "        scaled_img_hist = cv2.resize(equ, (64, 64))\n",
    "        \n",
    "        # m_4\n",
    "        combined_img = np.vstack((scaled_raw_img.reshape(64*64*3,1),scaled_img_hist.reshape(64*64,1)))\n",
    "        \n",
    "        \n",
    "        # reshaped final image\n",
    "        \n",
    "        # m_1\n",
    "        # final_img = scaled_raw_img.reshape(32*32*3,1)\n",
    "        \n",
    "        # m_2\n",
    "        # final_img = scaled_raw_img.reshape(64*64*3,1) \n",
    "        \n",
    "         # m_3\n",
    "        # final_img = scaled_img_hist.reshape(64*64,1)\n",
    "        \n",
    "        # m_4\n",
    "        \n",
    "        final_img = combined_img.reshape(64*64*4,1)\n",
    "        \n",
    "        \n",
    "        X.append(final_img)\n",
    "        y.append(class_dict[racer_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766ec70-dbc1-4c59-aecb-f31e89f46c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),16384).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e0e6a-b372-4e5d-bde0-08fe6168f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe_4 = Pipeline([('scaler', StandardScaler()), # Step 1: Standardize the data\n",
    "                 ('svc', SVC(kernel = 'rbf', C = 10)) # Step 2: Train a model\n",
    "                ])\n",
    "\n",
    "pipe_4.fit(X_train, y_train)\n",
    "m_4 = pipe_4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd57a2-d162-42e3-8bf5-0c93ae975a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f03c3b-5974-4258-b47b-0914a590357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a summary table of all the methods used and their performance\n",
    "\n",
    "methods = [\"m_1\", \"m_2\", \"m_3\",\"m_4\"]\n",
    "prediction_scores = [m_1, m_2, m_3, m_4]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Method\": methods, \"Prediction Scores\": prediction_scores})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47486185-5e78-46bf-bb56-4f1fee7819af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe7343f6-3a6b-4df1-a6b1-0bc2ed1007ea",
   "metadata": {},
   "source": [
    "## Create a classification report that provides precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3b7e1-38fb-4cea-ace9-97b912f19ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe_4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7862fe4-f00d-45c3-b53c-08c8693a8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like the best we can get is 59% accuracy \n",
    "# we might have to explore CNN \n",
    "\n",
    "# - https://www.youtube.com/watch?v=7HPwo4wnJeA\n",
    "# - https://www.codemag.com/Article/2205081/Implementing-Face-Recognition-Using-Deep-Learning-and-Support-Vector-Machines\n",
    "# - https://thinkingneuron.com/face-recognition-using-deep-learning-cnn-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0aef0-10c9-45d6-b58f-a5ad3e3d1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25eb1f-e4df-4d6b-820b-10a7fccfd1fd",
   "metadata": {},
   "source": [
    "### Choosing the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b934f8-cbea-496d-a396-67657bb470f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_clf = best_estimators['svm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2e36f-85bb-4338-aca5-c3e32a5f7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf92e1a-c2b7-4eb6-bf57-a9fac378df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8804c9e-7301-4e52-a5e6-c4401fe58f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict(X_test[5].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795f05b-2996-4b5f-9ea5-469c97020f82",
   "metadata": {},
   "source": [
    "### Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8058b-3ead-4922-855b-738e026ca928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37dcd4-43e8-40e2-a9be-f259603354f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874e23e-e37b-4bef-8538-675abdecb603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033bb71-3b65-4d18-92a5-40d993b41f2b",
   "metadata": {},
   "source": [
    "### Saving the model as pickle file  and create a class dictionary as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791f4a3-5dac-4c3e-868f-e7386184a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "import pickle\n",
    "\n",
    "pickle.dump(best_clf, open('saved_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d9b1b-0c73-4cea-8025-260efc12ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
